# AI Chat App Backend Environment Template
# Copy this file to .env and replace placeholder values

# Core Configuration
NODE_ENV=development
USE_MOCKS=false

# Stream Chat Configuration (Required)
# 1. Sign up at https://getstream.io/chat/
# 2. Create a new app
# 3. Copy API Key and Secret from Dashboard
STREAM_API_KEY=qt9h9tm8sqag
STREAM_API_SECRET=kap5d38baqp75sxp2nm6mx3ewe6wa73gxa6d4zd39m8bx3ynydyn9fb32grre9ct

# AI Model Configuration (Required)
# Using OpenRouter for multiple model access
# 1. Sign up at https://openrouter.ai/
# 2. Go to API Keys section
# 3. Create new secret key
OPENAI_API_KEY=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



# Model Selection (Optional - defaults to llama3.3 70B)
# Best options for your project:
# meta-llama/llama-3.3-70b-instruct:free (RECOMMENDED - 3.08B tokens, 66K context)
# deepseek/deepseek-r1-distill-llama-70b:free (Alternative - 1.74B tokens, 8K context)
# meta-llama/llama-3.3-8b-instruct:free (Lightweight - 432M tokens, 128K context)
AI_MODEL=meta-llama/llama-3.3-70b-instruct:free

# Tavily Search Configuration (Optional)
# 1. Sign up at https://tavily.com/
# 2. Get API key from dashboard
# Leave blank to disable web search functionality
TAVILY_API_KEY=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

# Observability Configuration (Optional)
# Backend Sentry DSN - Get from https://sentry.io/
# 1. Sign up at https://sentry.io/
# 2. Create new project for backend
# 3. Copy DSN from project settings
SENTRY_DSN="https://72af0510d3ae162902f0b84a1e51b307@o4510075027390464.ingest.us.sentry.io/4510075037810688"
# Frontend Sentry DSN - Get from https://sentry.io/
# 1. Create separate project for frontend
# 2. Copy DSN from project settings
VITE_SENTRY_DSN="https://919bdd7abd23ae1c8768948073929c07@o4510075027390464.ingest.us.sentry.io/4510075047641088"
LOG_LEVEL=info

# Server Configuration
PORT=3000